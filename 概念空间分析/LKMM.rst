.. Kenneth Lee 版权所有 2024

:Authors: Kenneth Lee
:Version: 0.1
:Date: 2024-07-23
:Status: Draft

LKMM
****

介绍
====

本文解释一下LKMM模型的原理。我在我的私有笔记上对这个做了较长时间的调研了，但这
个领域太多变化，我甚至觉得不一定有一个统一的认识，所以，到现在我还有不少认识和
LKMM的文档的说明不完全一致，但已经不多了，所以我想写这个公开笔记上总结，把这些
认识整合一下，以便我自己对我们指令集的进一步定义打一个概念空间的地基，同时也把
这些认识分享给更多的中文世界的开发者。

内存模型和内存序模型简介
------------------------

LKMM，Linux Kernel Memory Model，Linux内存模型，是一个对Linux内部API在内存上的
访问模式的建模。

内存模型是个很模糊的说法。在我写我们的指令架构手册的时候，我把所有内存访问的行
为特性都叫做内存模型，包括如何寻址，寻址的时候可以指定多大的访问范围，允许有什
么样的边际效应，地址如何翻译，原子性，内存序，Cache的使用，都看作是内存模型的
一部分。

但我也看过很多上下文仅仅把其中一个主题作为内存模型，比如有些资料会把虚拟地址翻
译特性称为内存模型。而我们现在讨论的LKMM，谈到内存模型，则主要指的是内存序模型。

那么什么是内存序模型呢？就是我们怎么认知我们的内存改变和读取的顺序。我们先从单
个CPU说起，比如你写这样的代码（假定内存的初值都是0）：

.. code-block:: c

  *((int *)0x12340000) = 1;
  *((int *)0x12340000) = 2;
  output(*((int *)0x12340000));

最后输出的应该是多少？显然应该是2，不能是1啊。因为我们对内存改变的顺序是有期望
的。总得是先改成1，再改成2，然后才读的，不能是先改成2，然后才读，最后才改成1的。
如果是后面这样，我们的程序就没法编了。

但如果我们把这些行为分解到多个CPU上，又怎么说呢？比如前两个指令放在一个CPU上，
最后一个指令放在另CPU上，这一点还成立吗？或者我们把问题更突出一点，我们把代码
改写成这样：::

       CPU1                             CPU2
  *((int *)0x12340000) = 1;      while (*((int *)0x12340000))!=1);
  *((int *)0x56780000) = 2;      output(*((int *)0x56780000));
  
output应该是多少？肯定是2吗？换句话说，我们承认在单个CPU上指令是有序的，但我们
承认这个顺序被其他CPU观察到的时候，这也是一样的吗？

有人可能认为“显然啊，把内存看作一个实体，这明明就是先修改了0x12340000再修改
0x56780000，CPU当然也应该先看到0x12340000被修改了，再看到0x56780000被修改啊。

这种想法可以用这张图来示意一下：

.. figure:: _static/mem_order.svg

你看我在图标注上用的语气，就能看出来，认为整片巨大的内存，非要等一个CPU修改完
才轮到下一个CPU，这不那么被待见。而且这确实不是一种“显而易见必须有的承诺”。没
人承诺过整片巨大的内存是个单独的实体啊，实际上它就是多片DIMM条组成的，甚至连在
不同的CPU的插槽上，再通过更慢的总线连在一起的。

所以，这种把CPU看作是一个整体排队接受访问请求的想法只能用作一种“学术意义上的基
线模型”，称为SC，Sequential Consistency。其他实用的商业实现（比如我们熟悉的
x86，ARM，PPC等等），几乎都不是这样保证的。

其实我们还可以换一个角度：我们为什么非要在CPU之间保序呢？本来就是CPU的辅助存储，
又不是用来做通讯的，我们能不能把通讯留给通讯，内存留给内存呢？

我曾经做过这方面的方案，让内存只在单个CPU上保序，如果两个CPU之间要通讯，只能通
过独立的“队列”服务来完成。这种方法在特定的场景上其实非常高效，特别是那种AMP信
号处理系统上，比如收到一个通知，向另几个服务提供另一组通知，进而引发更多的通知。
这种就很高效。但如果要发送的不是简单的控制信号，而是大量的数据，这种方法就不实
用了。比如你处理的是个报文系统，我们收到一个报文，先由层二协议处理，然后转给层
三，再转给层四，每层因为计算压力不同，部署在不同的CPU上，每层只是修改同一片内
存的不同位置，这种你很难把整个报文反反复复在不同的CPU之间发送的。到头来你只能
让内存访问是有序的，保证你的通知信号（虽然不必要，但这个信号常常就是内存变化本
身）发到另一个CPU的时候，所需的内存的更新已经到达这个CPU了。

所以这个没有什么办法，即使我们现在也提供了独立于内存CPU间信号通知手段，这种通
知机制还是必须和内存的更新顺序问题结合在一起来用，没法不考虑内存的实际读写顺序。

所以，这里的关键问题在于：内存不是系统中的一个单一的实体，而是很多很多，被很多
CPU共享的公共存储单元组成的。如果我们要求所有的访问者都要排队，那就会拖慢整个
系统计算的速度。这种排队，无论对于直接访问内存，还是通过CC协议在多个CPU之间同
步Cache的状态，都是一样的。


内存序模型
==========

这一章我们分编程、数学、物理三个模型来讨论内存序模型的更多细节。

内存序的编程模型
----------------

内存序模型在编程上主要解决这样一个问题：我在一个上下文中按某个顺序更新了几个内
存，我能否在另一个观察中保证我看到的顺序和这个顺序是一致的。

我们拿MP（Message Passing）模式来具象一下这个意思。考虑如下程序：::

        上下文1                   上下文2
     update_data();            wait_ready_flags();
     set_ready_flags();        use_data();

第一个上下文中，我们更新了数据（data），然后我们把两个上下文的通讯标记（flag）
置位。第二个上下文，我们等待flag被置位，然后我们再去使用data。我们编程上的期望
是：如果我这样写了，我的use_data()一定能用到update_data()所更新的数据。

我们前面说过了，如果我们可以写成这样：::

        上下文1                   上下文2
     push(data);                use_data(pop());

我们是不需要这种保序功能的，这才是我们原始的诉求，但我们前面也说过了，这种方法
效率不高。所以，我们只能对内存的更新顺序有所要求了。

这个问题，就算队列只发送一部分数据，比如只指针发过来，我们还是有保序要求的：::

        上下文1                   上下文2
     update_data();             data_p=pop()
     push(data_p);              use_data(*data_p);

我们就是要跨着两个上下文，让use_data()用到update_data()的数据。保证上下文1的更
新被“传播”到上下文2上。

在上面的讨论中，我们一直只说“上下文”，而不说CPU，因为我们编程的时候不一定有CPU
这个概念的，我们只有线程的概念，线程表示我们承诺了我们的行为是一个“序”，我们用
这个序来谈我们的期望。这个可以是我们某种编程库上的线程（比如pthread）的概念，
也可以是CPU的执行本身，因为CPU也维护了一种序。谈编程期望的时候我们不考虑这具体
是什么，但到实现到具体的上下文中，这还是需要考虑的。

内存序的数学模型
----------------

序这个问题，是有专门的数学理论的，它的基础就是集合论（Set Theory）。在这种理论
中，顺序表达为一种关系的集合。我们看个例子，比如下面这个顺序：::

  a -> b -> c -> d

从信息论上，我们的结论是a先于b，b先于c，c先于d。这样我们可以描述这个集合R：::

  R = {(a, b), (b, c), (c, d)}

但，在上面那个顺序中，我们是否还有“a先于c”这个信息？细想想，确实是有的，这也是
我们的信息的一部分。所以我们把这部分信息补充一下，上面这个集合应该这样写：::

  Q = {(a, b), (a, c), (a, d), (b, c), (c, d), (c, d)}

我们把可以用来组成关系的元素的集合称为E，上面这个例子中，E={a, b, c, d}。

这样，我们可以这样定义Q：Q是R的超级，对于任意元素x、y、z，x、y、z属于E，如果(x,
y)，（y, z)属于R，那么(x, z)属于Q。

Q称为R的迁移闭包。用后面我们会谈到的cat语言，这可以标记为：::

  Q = R+

有了一个这样的基础定义，我们就可以用集合的方法来对我们定义的各种序来进行数学运
算了。这就构成了一个数学模型，让我们可以研究各种序的组合关系。比如前面的MP问题，
我们这样定义这个问题：::

  令：
  up = update_data()
  s = set_ready_flags()
  w = wait_ready_flags()
  us = use_data();

  已知：
  上下文1指定的顺序：{(up, s)}
  上下文2指定的顺序：{(w, us)}

  问：需要增加什么条件才能保证：
  {(up, us)}总是成立？

这样就变成一个数学问题了。我们用集合论（其实还包括一些一阶谓词逻辑的理论）来研
究这个问题。

我这里的讨论不一定需要读者去深入学习集合论和一阶谓词逻辑（但看一些基本的内容是
有好处的），我这里先做一些基本的科普以便读者可以看懂后面的内容。

首先，我提醒读者注意：有了上面这样的定义后，我们一般理解的“序”就变成了一种特殊
的概念了，因为我们一般定义的一个序，不是这个泛泛的关系组合，我们还要求它无环
（不能a先于b，b先于c，c又先于a），可迁移，任意两者可比。这样的要求对比我们前面
关于“关系”的定义，其实约束已经非常多了。

在数学上，满足所有这些约束的，我们称为全序（Total Order）。如果仅仅是无环，可
迁移，而不是任意两者可比，这种我们称为偏序。如果能保证无环，那我们还可以认为这
是一个序，至少可比的时候还有先后的特征，一旦有了环，就无法确定谁在谁的前面了。
这种情况，我们就只能认为这是一种泛泛的“关系”，而无法把它称为“序”了。

为了方便，如果两个对象a, b可比，a先于b，我们会记做“a>b”。

内存序问题的关键期望，甚至不是一个序。我们只是要求所有行为的其中一部分，有一定
的先后关系。或者我们可以这样说：我们只是要求部分事件的子集，是一个序。

更多需要的数学基础概念，我们介绍概念的时候顺带描述，以支持读者可以不需要翻太多
的数学书就可以阅读下去。

数学建模工具
~~~~~~~~~~~~

你可以想象得到，推理“序”这种数学关系很难不使用计算机配合的，因为这种基于“集合”
而不是公式的推理，不穷举几乎没法做到。所以，我们的介绍很难不和数学工具结合在一
起。内存序这个领域，早期都是用一些通过的建模工具来做，比如之前分析过的
:doc:`Sail`\ 。还有更多的人使用自己开发的专用工具，现在慢慢都在统一到Herd（本
文写作的时候Herd的最新版本是7，它的语法在不同版本见是有更改的，所以我们确切一
点，我们按一般习惯称为Herd7）上了。

Herd使用一个类似Ocaml（Herd自己就是用Ocaml写的）的语法定义上面提到的集合论的运
算，这种定义文件用.cat作为扩展名，所以一般把这种定义的格式称为cat格式。现在很
多流行的平台，比如x86，ARM等都在使用cat格式，RISCV原来使用Sail，现在也切换到
cat上了，我们要讨论的LKMM现在也是用cat格式定义的。

Herd7的主页在这里：\ `herdtool7 <http://diy.inria.fr>`_\ 。上面有手册（但不是非常完善，很
多东西都没有深入解释，这里还有一个其他人写的总结：
`herd <https://mirrors.edge.kernel.org/pub/linux/kernel/people/paulmck/LWNLinuxMM/herd.html>`_
，可以参考。）我这里不打算介绍它的使用细节，我主要解释一下它的原理和基本
思路和概念。我自己第一次研究它的时候浪费了很多时间在这些基本思路和概念的理解上，
希望我这个介绍可以让读者避免走一样的弯路。

首先我们要理解，Herd7本身是个穷举功能。它的原理是你定义一个cat文件，说明所有的
约束，然后你再说明一个场景（比如像前面这种MP，这称为一个Litmus测试），它帮你穷
举你期望的某个条件是否可以成立。它不能给你完整的“定义”，不能确定你的定义满足某
个要求，它也不能给你证明两个定义是等价的。它就是在你的自由空间中给你穷举所有的
可能性。

也许我们可以这样理解：我们每个CPU都发出了一组内存操作，这组内存操作在每个观察
者看来，都有先有后，任何一种组合都可能。这是一个完全自由的集合变量空间。比如我
们观察前面提到的编程模型的up和us的关系，{(up, us)}可以是这个集合变量的一个解，
{(us, up)}也可以是这个集合的一个解。然后我们通过这个cat文件强制了一些条件，我
们能否把结果约束在{(up, us)}这一个解上？这就是Herd7帮我们穷举的东西。

注意了，我们这里说，Herd7只是给我们穷举一个可能性，它并不能输出约束之下的所有
解，因为这个计算量太大了，它就做不到。

所以，你只是给Herd7一个cat定义，说明你的约束，然后你给它一个检查条件（通常是一
段类似前面说的MP那样的一段代码），它告诉你你期望的那个目的（比如{(us, up)}一定
不是解的一部分）是否可以成立而已。

但用cat的格式说明一个规则，这种“标准化”的方法，有利于我们用一个统一的方法描述
问题。让实现CPU内存访问的芯片/硬件工程师和使用这个CPU的软件开发可以有统一的讨
论语言，这一点反而成了一件更重要的事情。即使我们不使用herd，cat也可以作为一种
“标准化”的讨论内存序问题的语言。

我们先看一个例子感受一下这个语言的而特征，然后随着这个解释更多的cat格式的概念。
比如下面是一个SC（前面提到的Sequential Consistency模型）的cat定义：::

  SC
  include "fences.cat"
  include "cos.cat"

  (* Atomic *)
  empty rmw & (fre;coe) as atom

  (* Sequential consistency *)
  show sm\id as si
  acyclic po | ((fr | rf | co);sm) as sc

两个头文件我们暂时不管，主要定义一些基本集合，我这里先解释一下这些基本集合的含
义：

* po：程序序，表示同一个CPU上的所有内存行为的序。
* fr: From Read，同位置读后写关系。
* rf: Read From，同位置写后读关系。
* co：Coherent Write，同位置的写后写关系。
* rmw：Read-Modify-Write，组成同一个原子指令的三个基本行为。
* fre：From-Read-External，跨CPU的fr。
* coe：Coherent Write External，跨CPU的co。
* sm: Same Memory，这个概念后面解释。
* id: 这表示所有事件自己和自己的关系（用来过滤事件用的内部常数）

然后我们看这个文件如何定义额外的约束。

首先，as xxxx这个语法表示某个约束的名字命名为xxxx。Herd完成穷举的后，如果找到
符合条件的例子会把这个例子的关系图输出来，类似这样：

.. figure:: _static/herd7-output.png

加上这个名字有助于可以在图上标记出这个关系，从而让你知道如何修正你的规则。后面
的show命令就是强制输出某个特定的关系。如果仅仅要看定义的规则，我们可以忽略它。

所以这个SC的定义仅仅定义了两个规则，一个叫atom，一个叫sc。

atom定义的是原子性规则，它说的是：rmw交fre;coe是一个空集。其中分号是“序列操作
符”，其实本质是复合函数。如果我们把关系集合看作是一个函数，每对关系就相当于函
数图像上的一个点，关系中的前一个元素就是定域域的输入，后一个元素就是值域的一个
元素。那么，两个关系集合的复合，就是把第一个集合的值域输入到第二个集合的定义域
中，得到第一个集合的输入和第二个集合的输出（中间有匹配不上的都放弃）。

比如我们计算{(a, b), (c, d)}:{(b, c), (d, e)}，输入a的时候，在第一个集合得到b，
用b作为输入在第二个集合中得到c，所以结果会得到(a, c)，如此类推，最终的结果就是
{(a, c), (c, e)}。

用序来理解就是：如果我们有两个序x和y，那么x;y就表示存在一个a-b-c这样的序，其
中a, b属于关系x，而b, c属于关系y。

所以这里fre;coe就表示下面CPU A的read_a和CPU C的write_a的关系：::

          CPU A                CPU B               CPU C
          read_a---\
                    \-(fre)--->write_a---\
                                          \-(coe)-->write_a
  
所有有这样的顺序关系的读写关系，都属于集合fre;coe。把这个集合交上rmw，rmw是一
条指令，表示同时做读-修改-写，这就表示上面CPU C的事情发生在CPU A上的那种情
况：::

          CPU A                CPU B
          read_a---\
                    \-(fre)--->write_a
                                 /
          write_a<------(coe)---/

所以这个意思就是说：如果A上的read_a和write_a两个事件属于同一个rwm指令，那么不
可能出现另一个CPU中的write_a，覆盖了a的值，还被A的write_a覆盖。这就是“rmw的原
子性”的定义。

我不知道读者是否注意到这一点：这个模型并不认为一个指令就是一个“内存事件”，这里
rmw本来只是一条指令，照理说就只产生一个事件，但实际上我们已经看到了，这有两个
事件。

所以这里的关键问题不在于几条指令，而在于我们有没有独立的行为可以单独关注到这个
事情。这个问题影响很多定义，比如一个原子的32位写操作，照理说应该是一个事件，它
也会被一个独立的读操作读到。但我们指令上也允许单独去读这个内存每个独立的字节。
为了说明这些每个独立的观察，我们也只能把这个原子操作定义成4个“内存事件”。如果
我们不需要推理那种情况，我们可以不分解这个定义，如果我们需要，那就只能分开，这
都会导致模型的不同。

所以，你不能认为模型就是“事实”，模型永远都是事实的“数字孪生”，你把什么东西放进
来讨论，你就只能模拟那些东西，它不是事实本身，也永远无法完全代表事实。

所以，其实就只有最后一个sc才是SC这个定义本身。为了理解这个定义，让我们先来理解
一下fr|rf|co的概念。fr表示一个地址上的值被一个写覆盖了。这听起来是个上帝视角，
没说是谁看见的。所以这样的定义存在，这个模型（herd7本身）已经承认内存至少在每
个独立可以观察的地址上是有“队列”的，这个fr指的就是在“内存”上，你再也读不到原来
的值了。

然后是rf，它表示一个读，读到了前一个写的内容。这是从发起这个读的观察者的眼中看
到的，如果(w, r)属于rf，那么r就是读到了w的值。至于它是通过cache读到的，还是通
过寄存器读到的，我们都不管。

最后是co，它表示coherent write，表示一个写，把前一个写覆盖了。和fr一样，这又是
一个上帝视角。这次让我画个图解释一下：

.. figure:: _static/co.svg

CPU有自己的Cache，当你要求访问内存，它当然可以选择写透Cache，一直写到内存上，
它也可以选择通知其他CPU，更新他们Cache的状态，让所有CPU都知道这个内存已经修改
了，再做下一个动作。这些动作的协议，称为Cache Coherency（CC）。如果你有实施CC
协议，无论你用的是什么方法，你在这个地址上总是形成一个序的。就是你的写，只要碰
到这个CC协议，你就会在CC这个接口上呈现一个顺序，让其他CPU在向这个CC接口请求数
据的时候，读到的数据就是符合这个序的。

但这不是必须的，如果我们不实现CC协议（就好像我们在很多CPU和设备之间通讯，要主
动更新Cache才能一些数据同步给设备），这一点并不成立。所以，你不要觉得Herd7给了
你所有的关于“关系”的自由度，其实它的语本身已经承认了很多东西了。

还有一个值得注意的点是：即使我们承认的CC协议，也不表示每个读写都会进入CC，因为
完全有可能在一个CPU上写了什么东西，在本CPU内部就被读走了，根本没有经过CC这个接
口。在后面的LKMM定义中，这种情形称为Forward。我们这里借用一些这个概念，也称为
Forward。

好了，下一个问题是sm是什么。这个其实我不知道，我几乎查不到关于这个概念的介绍，
无论是Herd7的文档还是它的源代码的注释。而我还没有足够时间直接看着代码去还原这
个概念，我猜它的意思应该是Same Memory。但如果你注意前面我们作为例子用的那个输
出，我是故意把sm这个关系show出来的，它除了和自己的关系，其他同地址的关系基本都
不认为是sm。但我最后还是认为它是Same Memory（带条件的），但在这个阶段，我们理
解的时候就当它是id好了。这样，“(fr|rf|co);sm”基本上可以简单理解为“(rf|rf|co)”。

那么（rf|rf|co）这个东西又是什么意思呢？本质上它就是我们可以“观察到的所有顺序”。
请想想这个问题：当我们认为“事件A发生在事件B前面”，我们说的是“我观察到A对B的执
行效果的影响”。注意这个说法，我们不是“先看到A的效果，再看到B的效果”，因为在“关
系”的世界中是没有时间的。我们看到的“序”，都是关系。事件上一个事件发生在另一个
事件的后面的唯一观感是后一个事件的发生是以前一个事件的结果为前提的。fr表示我在
CC接口上看到本来可以读到的数据x现在变成y了，所以写发生在读的“后面”。这才构成了
序。所以，fr|rf|co就是所有可以观察的序。从这个角度来说，也许我们可以把sm看作
“（如果有的话）其他的关联影响”，就是如果后一个事件还引起了一个连锁反应，那么这
种观察也考虑在内。而读后读不是一种观察，你读了一个值，随后又读了一次。上帝视角
这在时间上有先后，但在观察上没有任何区别。所以这种关系不是“观察”的一部分。我们
这里把这个定义为watch。

所以，po|watch，如果是无环（acyclic）的（构成一个序），就是SC。

这和我们一般理解的SC很不一样是不是？回想前面把整个内存看作一个实体，把所有访问
都排到这个队列上的情景，那个队列上的顺序不是才是SC吗？

问题是，那个队列是个上帝视角，没法用watch去确定事情发生了还是没有发生啊。再说
了，我们前面说，我们允许Forward了，那就有部分的watch没有发生在那个队列上了，这
也说不通啊。

所以我们干脆换一个思路，我们把po和watch放在一起，只要它构成一个序，那么我们已
经足够支持我们前面的编程模型需要的逻辑了。我们看一下这个MP的例子：

.. figure:: _static/acyclic_po_watch.svg

我们把up-s-w-us定义成一个“序”了，甚至不需要是全序或者偏序，那么编程上，我们就
能肯定us一定发生在up之后。为什么？既然这不是全序或者偏序，我们并没有可迁移性，
为什么可以认定(up, us)具有先后关系？很简单，因为他们只有三种可能的关系：

* 没关系
* up > us
* up < us

没关系你就不会写这个程序了，你写这个程序，它就只能有关系，如果up < us，那就构
成循环了，这破坏前面的定义。那就只能是up > us了。

然后我们拿这种定义用Herd去穷举一下，这确实保证了不会发生w rf s了，us无法rf up
的情况，那这个定义已经保证所有的po都能保序了。至于上帝视角的每个po的事件，是不
是按上帝的时间线按顺序一个个发生，这就超出我们“凡人”的认知范围了。

解释这个例子，给了我们一个很重要的启发：你会发现，所谓定义一个序，重点就是把所
有能保序的行为纳入一个集合，然后把它定义为acyclic的，这样我们就能保证这些行为
组成在“关系”是一个“序”，而我们可以利用这个序的性质，写出我们程序的因果了。

基本上就是集合和谓词定义，集合的主要运算符号我在附录（\ :ref:`cat_op`\ ）中放
了一个速查表，定义的语法和Ocaml是一样的，用let var=xxx的形式表达，比如：::

  let ppo = po & [RR]

剩下的主要就是定义规则的“谓词”，它其实就三个谓词：

* acyclic
* irreflexive
* empty

有两个我们都介绍过，最后这个irreflexive（非反身映射）需要解释一下，这个概念完
全来自数学，表示id的任何原属都不属于所述集合（不存在自己到自己的关系），这个集
合就是irreflexive的。

序的理论有一个概念叫DAG（Directed Acyclic Graph，有向无环图）。这个有向，就是
irreflexive；无环，就是acyclic，如果两者都成立，就构成一个AGD。有标准算法可以
把AGD所有可能的全序穷举出来。Herd7有一个叫linearisation(E, r)的函数可以完成这
样的穷举。

谓词前可以加~表示取反。

更多的语法可以自己看手册，我这里介绍的应该足够支持看本文了。


内存序的物理模型
----------------

前面介绍了数学模型，数学模型是边界而已，我们没法按着它来设计总线和CPU的，数学
上定义出来的原则，可以用来约束物理模型，但物理模型必然会引入额外的约束。反过来，
物理上有额外的约束，但数学模型不使用这个约束，其实也给软件带来来浪费。因为这个
地方本来没有自由度的，非要给一个自由度，软件就要加分支去处理，但这个分支从来不
进去，变成了浪费资源。

所以，甚至一下物理实现上的抽象模型，有助于我们优化数学模型的。

首先我们讨论一下po，早期而时候，po就是指的单个指令的顺序。但前面读者已经看到了，
实际上我们如果需要深入探讨各种关系的时候，po的事件集合就不能是指令。

甚至现在有些平台在把取指，Page Walk的访存行为也放到模型中来讨论，这个po的基本
事件集合就变得非常复杂了。

所以，我们以前可以很自然把po看作是一个全序，其实现在这个事情已经变得非常困难了。
我们只能认为po是一个偏序，甚至有时只能把它作为一个“序”，无法规定它的全序。像取
指和Page Walk这种很难预期的行为，常常是没有确定的先后关系的，比如，取指，往往
是一次取多条指令，然后同时发出执行的，这种情况你不能说序列是“取第一条指令，根
据第一条指令的要求访问内存，取第二条指令……”，你也不能确定地说，一定是“取8条指
令，执行8条指令，然后再取八条指令……”，你甚至不能说“必然在取指后才执行某条指令”，
因为这个取指行为完全有可能被缓存到CPU内部，导致根本不产生取指操作。

所以，如果可能，取指这个行为我们根本就不定义在一般的模型中，我们把它作为一个独
立的模型来定义，这样才能避免多余的复杂度。（但显然，某些平台不是这样做的。窃以
为不取也。）

按这样的观点，我们还是尽量让po接近一个全序，但这个全序的其中一段是无序的，类似
这样：::

  A -> B (a, b, c) -> C -> D (d, e, f)

ABCD是个全序，但B可以有多个子事件组成，这几个事件每个可以取代B构成这个全序，但
a, b, c之间是不一定有序的。比如B是一个SIMD指令，同时操作多条Lane，哪条Lane算在
前面？这不确定。但我们能肯定的是，SIMD指令前面的指令在任何一条Lane的前面，而
SIMD后面的指令在任何一条Lane的后面。在本文中，我把(a, b, c)这个集合称为B的无序
替代。如果a, b, c是有序的，我称为它是针对这个全序的有序替代。::

  B对po的无序提到：A ->a/b/c -> C -> D
  B对po的有序替代：A -> a -> b -> c -> C -> D

对CPU来说，内存操作是个慢速行为。在CPU的流水线中，一条指令可能需要经过取指，解
码，执行，访存，回写等多个阶段，每个阶段不过1到数个时钟周期不等，由于流水线的
作用，某条指令执行后面阶段的时候，执行前面阶段的硬件已经在执行下一条指令了，是
所以一条指令的执行时间不过一个或者几个时钟周期，但一次内存访问就要上百个时钟周
期。所以CPU有足够的理由缓存部分数据在CPU内部，一旦这个缓存存在了，就会出现我们
前面提到的Forward问题：数据可能不用经过CC接口就在内部消化了。

我们当然可以说如果它修改过这个数据，最终总要更新到CC接口上的。但别忘了，事情可
以这样发生的：在CPU内部写了一个值a，然后它被读走，然后CPU内部再写了一个值b，之
后b被写出去，那么a写这个行为就在内部被消化了，在CC接口上从来没有发生过。

这是CPU内部的情况，我们再看看CC接口上的行为。首先，我们忽略多层Cache的问题，因
为本质上，CPU一层看到的CC接口，已经代表内存的态度了，CC接口的下一层如果还有一
层Cache，那么是这个上层的CC接口通过CC接口再去为下一层的一致性负责，对CPU来说，
它只考虑CC接口的承诺就行了，下一层都由这个地一层的接口代表了，对运行在CPU里面
的程序来说，下一层的逻辑是可以忽略的：

.. figure:: _static/cc_if.svg

我们更关心的是第一层的CC协议到底怎么承诺这个序的。这就又涉及到CPU内部的缓冲的
问题了。

todo：待继续。

LKMM
====

todo：LKMM模型和CPU模型的区别和LKMM的细节

附录
====

.. _`cat_op`:

cat主要操作符的解释
-------------------

* \|, &, \，;表示并集，交集，差集和序列。

* {}表示空集，++是元素加到集合中。

* r+和r\*分别表示r的迁移闭包和迁移反射闭包。0表示空集。r^-1表示r的反射。r?表示
  r加上iden。（注意了，herd中这个反射包括所有事件的全集，但我看数学上的定义似
  乎只包括r包含的元素本身。)

  所谓迁移反射的定义是：r\* =r+ | id

* R*W表示R和W的笛卡尔乘积。

* [E]=E*E & iden

从序列的角度来理解，上面这个符号体系其实有点像正则表达式。

如果我们有一个序列r1;r2;r3，这个序列定义了一个这样的关系：::

  a--(r1)-->b--(r2)-->c--(r3)-->d

这样的序列中的a->d关系。

如果我们加上一个+号，变成这样：r1;r2+;r3，这表示watch2这个关系还需
要存在，但可以有多个：::

  a--(r1)-->b--(r2)-->c--(r3)-->d
  a--(r1)-->b--(r2)-->c--(r2)-->c1--(r3)-->d
  a--(r1)-->b--(r2)-->c--(r2)-->c1--(r2)-->c2--(r3)-->d

这些情况的序列，都符合我们定义的a->d关系。

如果我们加上一个\*号，变成：r1;r2*;r3，这表示r2这个关系可以有任意多个，那么除
了前面的，这个也符合条件：::

  a--(r1)-->b--(r3)-->d

如果我们家一个?号，变成：r1;r2?;r3，这表示r2可选，那么这两种情况都符合定义：::

  a--(r1)-->b--(r3)-->d
  a--(r1)-->b--(r2)-->c--(r3)-->d

这和正则表达式的通配符是一样的。而[]操作符可以用于过滤，比如[R];r1;r2;r3;[W]，
如果R表示所有的读，W表示所有的写。那么这个表示在r1;r2;r3定义的序列中，前后的两
个操作必须一个是读，一个是写。

如果我们写成这样：r1;[R];r2，这表示连接r1和r2的那个操作必须是个读。对于下面这
种情况：::

  a--(r1)-->b--(r2)-->d

它要求b必须是个读。理解这一点，就比较容易读懂LKMM的各种定义了。
